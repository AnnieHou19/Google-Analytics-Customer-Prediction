{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading the data and have a quick look","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-09T04:20:09.317698Z","iopub.execute_input":"2021-11-09T04:20:09.318103Z","iopub.status.idle":"2021-11-09T04:20:09.353394Z","shell.execute_reply.started":"2021-11-09T04:20:09.318004Z","shell.execute_reply":"2021-11-09T04:20:09.352583Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Necessary librarys\nimport os # it's a operational system library, to set some informations\nimport random # random is to generate random values\n\nimport pandas as pd # to manipulate data frames \nimport numpy as np # to work with matrix\nfrom scipy.stats import kurtosis, skew # it's to explore some statistics of numerical values\n\nimport matplotlib.pyplot as plt # to graphics plot\nimport seaborn as sns # a good library to graphic plots\ncolor = sns.color_palette()\nimport squarify # to better understand proportion of categorys - it's a treemap layout algorithm\n\nfrom sklearn.preprocessing import StandardScaler \nfrom scipy import stats #The sklearn. preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.\n\n# Importing librarys to use on interactive graphs\nfrom plotly.offline import init_notebook_mode, iplot, plot \nimport plotly.graph_objs as go \n\nimport json # to convert json in df\nfrom pandas.io.json import json_normalize # to normalize the json file\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfrom sklearn import model_selection, preprocessing, metrics\nimport lightgbm as lgb\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\n\n# to set a style to all graphs\nplt.style.use('fivethirtyeight')\ninit_notebook_mode(connected=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:09.355016Z","iopub.execute_input":"2021-11-09T04:20:09.355453Z","iopub.status.idle":"2021-11-09T04:20:11.699072Z","shell.execute_reply.started":"2021-11-09T04:20:09.355420Z","shell.execute_reply":"2021-11-09T04:20:11.698038Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"columns = ['device', 'geoNetwork', 'totals', 'trafficSource'] # Columns that have json format\n\ndir_path = \"/kaggle/input/ga-customer-revenue-prediction/\" \n\n# p is a fractional number to skiprows and read just a random sample of the our dataset. \np = 0.07 # *** In this case we will use 50% of data set *** #\n\n#Code to transform the json format columns in table\ndef json_read(df):\n    #joining the [ path + df received]\n    data_frame = dir_path + df\n    \n    #Importing the dataset\n    df = pd.read_csv(data_frame, \n                     converters={column: json.loads for column in columns}, # loading the json columns properly\n                     dtype={'fullVisitorId': 'str'}, # transforming this column to string\n                     skiprows=lambda i: i>0 and random.random() > p)# Number of rows that w\n    for column in columns: #loop to finally transform the columns in data frame\n        #It will normalize and set the json to a table\n        column_as_df = json_normalize(df[column]) \n        # here will be set the name using the category and subcategory of json columns\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns] \n        # after extracting the values, let drop the original columns\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n        \n    # Printing the shape of dataframes that was imported     \n    print(f\"Loaded {os.path.basename(data_frame)}. Shape: {df.shape}\")\n    return df # returning the df after importing and transforming\n","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:11.700653Z","iopub.execute_input":"2021-11-09T04:20:11.701168Z","iopub.status.idle":"2021-11-09T04:20:11.716017Z","shell.execute_reply.started":"2021-11-09T04:20:11.701121Z","shell.execute_reply":"2021-11-09T04:20:11.714766Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%%time \n# %%time is used to calculate the timing of code chunk execution #\n\n# We will import the data using the name and extension that will be concatenated with dir_path\ndf_train = json_read(\"train.csv\") \n# The same to test dataset\n#df_test = json_read(\"test.csv\") ","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:11.718286Z","iopub.execute_input":"2021-11-09T04:20:11.718665Z","iopub.status.idle":"2021-11-09T04:20:44.404079Z","shell.execute_reply.started":"2021-11-09T04:20:11.718627Z","shell.execute_reply":"2021-11-09T04:20:44.402924Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# This command shows the first 5 rows of our dataset\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:44.405834Z","iopub.execute_input":"2021-11-09T04:20:44.406111Z","iopub.status.idle":"2021-11-09T04:20:44.460003Z","shell.execute_reply.started":"2021-11-09T04:20:44.406080Z","shell.execute_reply":"2021-11-09T04:20:44.458902Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:44.461628Z","iopub.execute_input":"2021-11-09T04:20:44.461893Z","iopub.status.idle":"2021-11-09T04:20:44.870380Z","shell.execute_reply.started":"2021-11-09T04:20:44.461854Z","shell.execute_reply":"2021-11-09T04:20:44.869684Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# First thing first, analyzing totals.transactionRevenue\nSince we are predicting the natural log of sum of all transactions of the user, let us sum up the transaction revenue at user level and take a log and visulize in a scatter plot","metadata":{}},{"cell_type":"code","source":"df_train[\"totals.transactionRevenue\"] = df_train[\"totals.transactionRevenue\"].astype('float')\ngdf = df_train.groupby(\"fullVisitorId\")[\"totals.transactionRevenue\"].sum().reset_index()\n\nplt.figure(figsize=(8,6))\nplt.scatter(range(gdf.shape[0]), np.sort(np.log1p(gdf[\"totals.transactionRevenue\"].values)))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('TransactionRevenue', fontsize=12)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:44.872859Z","iopub.execute_input":"2021-11-09T04:20:44.873222Z","iopub.status.idle":"2021-11-09T04:20:45.435965Z","shell.execute_reply.started":"2021-11-09T04:20:44.873175Z","shell.execute_reply":"2021-11-09T04:20:45.435209Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"This visual has confirmed 80/20 rule that a small percentage of customers product most of the revenue. Therefore, the marketing team are in need of making smart marketing strategies to reach those high value customers. ","metadata":{}},{"cell_type":"code","source":"nzi = pd.notnull(df_train[\"totals.transactionRevenue\"]).sum()\nnzr = (gdf[\"totals.transactionRevenue\"]>0).sum()\nprint(\"Number of instances in train set with non-zero revenue : \", nzi, \" and ratio is : \", nzi / df_train.shape[0])\nprint(\"Number of unique customers with non-zero revenue : \", nzr, \"and the ratio is : \", nzr / gdf.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:45.437302Z","iopub.execute_input":"2021-11-09T04:20:45.438676Z","iopub.status.idle":"2021-11-09T04:20:45.450820Z","shell.execute_reply.started":"2021-11-09T04:20:45.438579Z","shell.execute_reply":"2021-11-09T04:20:45.449931Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"So the ratio of customers with revenue vs. customer with no revenue is 1.3% ","metadata":{}},{"cell_type":"markdown","source":"Before doing any further analysis, I'm going to find out the constant values that is not useful and save time on manipulating and processing","metadata":{}},{"cell_type":"code","source":"discovering_consts = [col for col in df_train.columns if df_train[col].nunique() == 1]\nprint(\"Columns with just one value: \", len(discovering_consts), \"columns\")\nprint(\"Name of constant columns: \\n\", discovering_consts)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:45.452315Z","iopub.execute_input":"2021-11-09T04:20:45.453211Z","iopub.status.idle":"2021-11-09T04:20:46.369176Z","shell.execute_reply.started":"2021-11-09T04:20:45.453162Z","shell.execute_reply":"2021-11-09T04:20:46.368253Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#dropping the constant colums\ndf_train.drop(columns = discovering_consts)","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:46.372196Z","iopub.execute_input":"2021-11-09T04:20:46.373370Z","iopub.status.idle":"2021-11-09T04:20:46.635362Z","shell.execute_reply.started":"2021-11-09T04:20:46.373301Z","shell.execute_reply":"2021-11-09T04:20:46.634613Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:46.636806Z","iopub.execute_input":"2021-11-09T04:20:46.637590Z","iopub.status.idle":"2021-11-09T04:20:47.150200Z","shell.execute_reply.started":"2021-11-09T04:20:46.637551Z","shell.execute_reply":"2021-11-09T04:20:47.148989Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**totals.transactionRevenue vs. Device**","metadata":{}},{"cell_type":"code","source":"#totals.transactionRevenue correlation matrics\ndef horizontal_bar_chart(cnt_srs, color):\n    trace = go.Bar(\n        y=cnt_srs.index[::-1],\n        x=cnt_srs.values[::-1],\n        showlegend=False,\n        orientation = 'h',\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\n# Device Browser\ncnt_srs = df_train.groupby('device.browser')['totals.transactionRevenue'].agg(['size', 'count', 'mean'])\ncnt_srs.columns = [\"count\", \"count of non-zero revenue\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace1 = horizontal_bar_chart(cnt_srs[\"count\"].head(10), 'rgba(50, 171, 96, 0.6)')\ntrace2 = horizontal_bar_chart(cnt_srs[\"count of non-zero revenue\"].head(10), 'rgba(50, 171, 96, 0.6)')\ntrace3 = horizontal_bar_chart(cnt_srs[\"mean\"].head(10), 'rgba(50, 171, 96, 0.6)')\n\n# Device Category\ncnt_srs = df_train.groupby('device.deviceCategory')['totals.transactionRevenue'].agg(['size', 'count', 'mean'])\ncnt_srs.columns = [\"count\", \"count of non-zero revenue\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace4 = horizontal_bar_chart(cnt_srs[\"count\"].head(10), 'rgba(71, 58, 131, 0.8)')\ntrace5 = horizontal_bar_chart(cnt_srs[\"count of non-zero revenue\"].head(10), 'rgba(71, 58, 131, 0.8)')\ntrace6 = horizontal_bar_chart(cnt_srs[\"mean\"].head(10), 'rgba(71, 58, 131, 0.8)')\n\n# Operating system\ncnt_srs = df_train.groupby('device.operatingSystem')['totals.transactionRevenue'].agg(['size', 'count', 'mean'])\ncnt_srs.columns = [\"count\", \"count of non-zero revenue\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace7 = horizontal_bar_chart(cnt_srs[\"count\"].head(10), 'rgba(246, 78, 139, 0.6)')\ntrace8 = horizontal_bar_chart(cnt_srs[\"count of non-zero revenue\"].head(10),'rgba(246, 78, 139, 0.6)')\ntrace9 = horizontal_bar_chart(cnt_srs[\"mean\"].head(10),'rgba(246, 78, 139, 0.6)')\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=3, vertical_spacing=0.04, \n                          subplot_titles=[\"Device Browser - Count\", \"Device Browser - Non-zero Revenue Count\", \"Device Browser - Mean Revenue\",\n                                          \"Device Category - Count\",  \"Device Category - Non-zero Revenue Count\", \"Device Category - Mean Revenue\", \n                                          \"Device OS - Count\", \"Device OS - Non-zero Revenue Count\", \"Device OS - Mean Revenue\"])\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 2, 1)\nfig.append_trace(trace5, 2, 2)\nfig.append_trace(trace6, 2, 3)\nfig.append_trace(trace7, 3, 1)\nfig.append_trace(trace8, 3, 2)\nfig.append_trace(trace9, 3, 3)\n\nfig['layout'].update(height=1200, width=1200, paper_bgcolor='rgb(233,233,233)', title=\"Device Plots\")\npy.iplot(fig, filename='device-plots')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:47.151866Z","iopub.execute_input":"2021-11-09T04:20:47.152132Z","iopub.status.idle":"2021-11-09T04:20:48.346143Z","shell.execute_reply.started":"2021-11-09T04:20:47.152099Z","shell.execute_reply":"2021-11-09T04:20:48.345242Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"* Device distribution looks similar on both the count and the count of non-zero revenue plots. And the majority of the traffic comes from Chrome for both zero and non-zero revenue traffic\n* For device category, desktop is getting way more traffic for both zero and non-zero traffic than mobile and desktop. And the average revenue on desktop is also higher\n* For device category, desktop is getting way more traffic for both zero and non-zero traffic than mobile and desktop. And the average revenue on desktop is also higher\n* For device operating system,  windows has the highest number of counts while macintosh has the highest non-zero revenue count.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"**totals.transactionRevenue vs. Geo**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Continent\ncnt_srs = df_train.groupby('geoNetwork.continent')['totals.transactionRevenue'].agg(['size', 'count', 'mean'])\ncnt_srs.columns = [\"count\", \"count of non-zero revenue\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace1 = horizontal_bar_chart(cnt_srs[\"count\"].head(10), 'rgba(58, 71, 80, 0.6)')\ntrace2 = horizontal_bar_chart(cnt_srs[\"count of non-zero revenue\"].head(10), 'rgba(58, 71, 80, 0.6)')\ntrace3 = horizontal_bar_chart(cnt_srs[\"mean\"].head(10), 'rgba(58, 71, 80, 0.6)')\n\n# Sub-continent\ncnt_srs = df_train.groupby('geoNetwork.subContinent')['totals.transactionRevenue'].agg(['size', 'count', 'mean'])\ncnt_srs.columns = [\"count\", \"count of non-zero revenue\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace4 = horizontal_bar_chart(cnt_srs[\"count\"], 'orange')\ntrace5 = horizontal_bar_chart(cnt_srs[\"count of non-zero revenue\"], 'orange')\ntrace6 = horizontal_bar_chart(cnt_srs[\"mean\"], 'orange')\n\n# Country\ncnt_srs = df_train.groupby('geoNetwork.country')['totals.transactionRevenue'].agg(['size', 'count', 'mean'])\ncnt_srs.columns = [\"count\", \"count of non-zero revenue\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace7 = horizontal_bar_chart(cnt_srs[\"count\"].head(10), 'blue')\ntrace8 = horizontal_bar_chart(cnt_srs[\"count of non-zero revenue\"].head(10), 'blue')\ntrace9 = horizontal_bar_chart(cnt_srs[\"mean\"].head(10), 'blue')\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=3, vertical_spacing=0.08, horizontal_spacing=0.15, \n                          subplot_titles=[\"Continent - Count\", \"Continent - Non-zero Revenue Count\", \"Continent - Mean Revenue\",\n                                          \"Sub Continent - Count\",  \"Sub Continent - Non-zero Revenue Count\", \"Sub Continent - Mean Revenue\",\n                                          \"Country - Count\", \"Country - Non-zero Revenue Count\", \"Country - Mean Revenue\"])\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 2, 1)\nfig.append_trace(trace5, 2, 2)\nfig.append_trace(trace6, 2, 3)\nfig.append_trace(trace7, 3, 1)\nfig.append_trace(trace8, 3, 2)\nfig.append_trace(trace9, 3, 3)\n\nfig['layout'].update(height=1500, width=1200, paper_bgcolor='rgb(233,233,233)', title=\"Geography Plots\")\npy.iplot(fig, filename='geo-plots')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:48.348000Z","iopub.execute_input":"2021-11-09T04:20:48.348473Z","iopub.status.idle":"2021-11-09T04:20:48.621663Z","shell.execute_reply.started":"2021-11-09T04:20:48.348428Z","shell.execute_reply":"2021-11-09T04:20:48.620814Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"* Organic has the highest number of count, while referral has the highest number of non-zero revenue count.Indicating referall is the most efficient chanel in driving revenue for G Store\n","metadata":{}},{"cell_type":"code","source":"# Medium\ncnt_srs = df_train.groupby('trafficSource.medium')['totals.transactionRevenue'].agg(['size', 'count', 'mean'])\ncnt_srs.columns = [\"count\", \"count of non-zero revenue\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace1 = horizontal_bar_chart(cnt_srs[\"count\"].head(10), 'rgba(58, 71, 80, 0.6)')\ntrace2 = horizontal_bar_chart(cnt_srs[\"count of non-zero revenue\"].head(10), 'rgba(58, 71, 80, 0.6)')\ntrace3 = horizontal_bar_chart(cnt_srs[\"mean\"].head(10), 'rgba(58, 71, 80, 0.6)')\n\n# Source\ncnt_srs = df_train.groupby('trafficSource.source')['totals.transactionRevenue'].agg(['size', 'count', 'mean'])\ncnt_srs.columns = [\"count\", \"count of non-zero revenue\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace4 = horizontal_bar_chart(cnt_srs[\"count\"], 'orange')\ntrace5 = horizontal_bar_chart(cnt_srs[\"count of non-zero revenue\"], 'orange')\ntrace6 = horizontal_bar_chart(cnt_srs[\"mean\"], 'orange')\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=3, vertical_spacing=0.08, horizontal_spacing=0.15, \n                          subplot_titles=[\"Medium - Count\", \"Medium - Non-zero Revenue Count\", \"Medium - Mean Revenue\",\n                                          \"Source - Count\",  \"Source- Non-zero Revenue Count\", \"Source - Mean Revenue\",\n                                          \"Keyword - Count\", \"Keyword - Non-zero Revenue Count\", \"Keyword - Mean Revenue\"])\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 2, 1)\nfig.append_trace(trace5, 2, 2)\nfig.append_trace(trace6, 2, 3)\nfig.append_trace(trace7, 3, 1)\nfig.append_trace(trace8, 3, 2)\nfig.append_trace(trace9, 3, 3)\n\nfig['layout'].update(height=1500, width=1200, paper_bgcolor='rgb(233,233,233)', title=\"Geography Plots\")\npy.iplot(fig, filename='geo-plots')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:48.623744Z","iopub.execute_input":"2021-11-09T04:20:48.624270Z","iopub.status.idle":"2021-11-09T04:20:48.839534Z","shell.execute_reply.started":"2021-11-09T04:20:48.624208Z","shell.execute_reply":"2021-11-09T04:20:48.838545Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"* The majority of the zero and non-zero revenue traffic is coming from North America\n* Within North America, the majority of the zero and non-zero revenue traffic is coming from America","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df_train.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2021-11-09T04:20:48.840851Z","iopub.execute_input":"2021-11-09T04:20:48.841077Z","iopub.status.idle":"2021-11-09T04:20:50.211745Z","shell.execute_reply.started":"2021-11-09T04:20:48.841050Z","shell.execute_reply":"2021-11-09T04:20:50.210887Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}